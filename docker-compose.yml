version: '3.7'
services:
    postgres:
        image: postgres:9.6
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        logging:
            options:
                max-size: 10m
                max-file: "3"

    webserver:
        image: puckel/docker-airflow:1.10.9
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - EXECUTOR=Local
        logging:
            options:
                max-size: 10m
                max-file: "3"
        volumes:
            - ./dags:/usr/local/airflow/dags
            - ./data:/usr/local/airflow/data
        ports:
            - "8079:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3

    streamsets:
      build:
        context: "."
        args:
          SDC_LIBS: streamsets-datacollector-apache-kafka_2_0-lib
      ports:
        - 18630:18630
      volumes:
        - ./sdc-data:/data
        - ./credentials:/opt/credentials

    vertica:
        image: dataplatform/docker-vertica
        ports:
          - 5433:5433
        volumes:
          - ./input/:/tmp/input

 # HDFS namenode
    namenode:
      image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
      ports:
        - 9870:9870
        - 9000:9000
      volumes:
        - hadoop_namenode:/hadoop/dfs/name
      environment:
        - CLUSTER_NAME=test
      env_file:
        - ./hadoop.env

  # HDFS datanode
    datanode:
      image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
      volumes:
        - hadoop_datanode:/hadoop/dfs/data
      environment:
        SERVICE_PRECONDITION: "namenode:9870"
      env_file:
        - ./hadoop.env

volumes:
  hadoop_namenode:
  hadoop_datanode:
#    spark-master:
#      image: bde2020/spark-master:2.4.5-hadoop2.7
#      container_name: spark-master
#      ports:
#        - "8083:8080"
#        - "7077:7077"
#      environment:
#        - INIT_DAEMON_STEP=setup_spark
#    spark-worker-1:
#      image: bde2020/spark-worker:2.4.5-hadoop2.7
#      container_name: spark-worker-1
#      depends_on:
#        - spark-master
#      ports:
#        - "8081:8084"
#      environment:
#        - "SPARK_MASTER=spark://spark-master:7077"
